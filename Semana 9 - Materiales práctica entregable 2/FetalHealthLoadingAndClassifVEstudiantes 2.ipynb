{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float:left\" width=\"70%\" src=\"pics/escudo_COLOR_1L_DCHA.png\">\n",
    "<img style=\"float:right\" width=\"15%\" src=\"pics/PythonLogo.svg\">\n",
    "<br style=\"clear:both;\">\n",
    "\n",
    "# Evaluación de métodos de clasificación para la base de datos *Fetal Health*\n",
    "\n",
    "Este *Notebook* contiene el trabajo necesario para cargar el fichero *.csv* de la base de datos de **Kaggle** sobre *salud fetal*, así como para aplicar diferentes tipos de métodos de clasificación sobre dicha base de datos.\n",
    "\n",
    "## Autor\n",
    "- Pedro Latorre Carmona\n",
    "\n",
    "### Curso\n",
    "- 2022-2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaggle** es, digamos, un repositorio, donde podemos encontrar bases de datos, así como diferentes tipos de métodos (código), para tareas que pueden ir desde la clasificación, regresión, por citar sólo dos ejemplos:\n",
    "\n",
    "https://www.kaggle.com/\n",
    "\n",
    "Dentro de **Kaggle**, vamos a trabajar con la base de datos de **Fetal Health**, la cual puede encontrarse en:\n",
    "\n",
    "https://www.kaggle.com/datasets/andrewmvd/fetal-health-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Tal y como se establece en esta página:\n",
    "\n",
    "\"La reducción de la mortalidad infantil se refleja en varios de los Objetivos de Desarrollo Sostenible de las Naciones Unidas y es un indicador clave del progreso humano. La ONU espera que para 2030, los países pongan fin a las muertes prevenibles de recién nacidos y niños menores de 5 años, con el objetivo de reducir la mortalidad de menores de 5 años al menos a 25 por cada 1000 nacidos vivos.\n",
    "\n",
    "Paralelamente a la noción de mortalidad infantil está, por supuesto, la mortalidad materna, que representa 295000 muertes durante y después del embarazo y el parto (a fecha de $2017$). La gran mayoría de estas muertes ($94\\%$) ocurrieron en entornos de bajos recursos y la mayoría podría haberse evitado.\n",
    "\n",
    "A la luz de lo mencionado anteriormente, los cardiotocogramas (CTG) son una opción simple y económicamente accesible para evaluar la salud fetal, lo que permite a los profesionales de la salud tomar medidas para prevenir la mortalidad infantil y materna. El equipo en sí funciona enviando pulsos de ultrasonido y leyendo su respuesta, establciendo la frecuencia cardíaca fetal (FCF), los movimientos fetales, las contracciones uterinas y más.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Datos\n",
    "\n",
    "Este conjunto de datos contiene $2126$ registros de características extraídas de exámenes de cardiotocograma, que luego fueron clasificados por tres obstetras expertos, en $3$ clases:\n",
    "\n",
    "1. Normal\n",
    "2. Sospechosa\n",
    "3. Patológica\n",
    "\n",
    "Esta base de datos es en realidad un fichero **.csv** que tiene una tabla en la que cada fila es un **dato** asociado a un **ejemplo**. Dentro de cada fila (data), tenemos un conjunto de **atributos** o características, que conforman el vector con el que describimos dicho dato (denominado **vector de características**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Objetivo\n",
    "\n",
    "El objetivo del trabajo a continuación es crear el conjunto de datos $(\\mathbf{X,Y})$, generar los conjuntos de **entrenamiento** y **test** y aplicar dos métodos de clasificación:\n",
    "\n",
    "1. Support Vector Machines (SVM)\n",
    "2. Multilayer perceptron\n",
    "\n",
    "Se tendrán que mostrar los resultados de clasificación de diferentes formas, y analizarlos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Para el método de clasificación de **Support Vector Machines** (SVMs), se dará en clase una pequeña introducción, aunque se puede encontrar información muy fácilmente, ya que es un método muy usado:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Support_vector_machine\n",
    "\n",
    "El clasificador denominado **Perceptrón multicapa** (**Multilayer perceptron**), no lo veremos, simplemente lo usaremos, aunque se puede encontrar información, por ejemplo, en (por ejemplo):\n",
    "\n",
    "https://es.wikipedia.org/wiki/Perceptr%C3%B3n_multicapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Carga de la base de datos y aplicación de los métodos de clasificación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para gestionar los datos en el fichero **.csv**, vamos a utilizar la estructura de datos de **Pandas dataframe**, cuyos detalles pueden encontrarse en:\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
    "\n",
    "En concreto, vamos a utilizar la opción que nos permite leer ficheros **.csv**, y que se encuentra en:\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Importación de librerías\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Datos\n",
    "'''\n",
    "\n",
    "path = \"./FetalData\"\n",
    "filename = path + os.sep + \"fetal_health.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga del fichero csv como un *data frame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizad la opción \"pd.read_csv\"\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline value</th>\n",
       "      <th>accelerations</th>\n",
       "      <th>fetal_movement</th>\n",
       "      <th>uterine_contractions</th>\n",
       "      <th>light_decelerations</th>\n",
       "      <th>severe_decelerations</th>\n",
       "      <th>prolongued_decelerations</th>\n",
       "      <th>abnormal_short_term_variability</th>\n",
       "      <th>mean_value_of_short_term_variability</th>\n",
       "      <th>percentage_of_time_with_abnormal_long_term_variability</th>\n",
       "      <th>...</th>\n",
       "      <th>histogram_min</th>\n",
       "      <th>histogram_max</th>\n",
       "      <th>histogram_number_of_peaks</th>\n",
       "      <th>histogram_number_of_zeroes</th>\n",
       "      <th>histogram_mode</th>\n",
       "      <th>histogram_mean</th>\n",
       "      <th>histogram_median</th>\n",
       "      <th>histogram_variance</th>\n",
       "      <th>histogram_tendency</th>\n",
       "      <th>fetal_health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>137.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>142.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>117.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2126 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      baseline value  accelerations  fetal_movement  uterine_contractions  \\\n",
       "0              120.0          0.000           0.000                 0.000   \n",
       "1              132.0          0.006           0.000                 0.006   \n",
       "2              133.0          0.003           0.000                 0.008   \n",
       "3              134.0          0.003           0.000                 0.008   \n",
       "4              132.0          0.007           0.000                 0.008   \n",
       "...              ...            ...             ...                   ...   \n",
       "2121           140.0          0.000           0.000                 0.007   \n",
       "2122           140.0          0.001           0.000                 0.007   \n",
       "2123           140.0          0.001           0.000                 0.007   \n",
       "2124           140.0          0.001           0.000                 0.006   \n",
       "2125           142.0          0.002           0.002                 0.008   \n",
       "\n",
       "      light_decelerations  severe_decelerations  prolongued_decelerations  \\\n",
       "0                   0.000                   0.0                       0.0   \n",
       "1                   0.003                   0.0                       0.0   \n",
       "2                   0.003                   0.0                       0.0   \n",
       "3                   0.003                   0.0                       0.0   \n",
       "4                   0.000                   0.0                       0.0   \n",
       "...                   ...                   ...                       ...   \n",
       "2121                0.000                   0.0                       0.0   \n",
       "2122                0.000                   0.0                       0.0   \n",
       "2123                0.000                   0.0                       0.0   \n",
       "2124                0.000                   0.0                       0.0   \n",
       "2125                0.000                   0.0                       0.0   \n",
       "\n",
       "      abnormal_short_term_variability  mean_value_of_short_term_variability  \\\n",
       "0                                73.0                                   0.5   \n",
       "1                                17.0                                   2.1   \n",
       "2                                16.0                                   2.1   \n",
       "3                                16.0                                   2.4   \n",
       "4                                16.0                                   2.4   \n",
       "...                               ...                                   ...   \n",
       "2121                             79.0                                   0.2   \n",
       "2122                             78.0                                   0.4   \n",
       "2123                             79.0                                   0.4   \n",
       "2124                             78.0                                   0.4   \n",
       "2125                             74.0                                   0.4   \n",
       "\n",
       "      percentage_of_time_with_abnormal_long_term_variability  ...  \\\n",
       "0                                                  43.0       ...   \n",
       "1                                                   0.0       ...   \n",
       "2                                                   0.0       ...   \n",
       "3                                                   0.0       ...   \n",
       "4                                                   0.0       ...   \n",
       "...                                                 ...       ...   \n",
       "2121                                               25.0       ...   \n",
       "2122                                               22.0       ...   \n",
       "2123                                               20.0       ...   \n",
       "2124                                               27.0       ...   \n",
       "2125                                               36.0       ...   \n",
       "\n",
       "      histogram_min  histogram_max  histogram_number_of_peaks  \\\n",
       "0              62.0          126.0                        2.0   \n",
       "1              68.0          198.0                        6.0   \n",
       "2              68.0          198.0                        5.0   \n",
       "3              53.0          170.0                       11.0   \n",
       "4              53.0          170.0                        9.0   \n",
       "...             ...            ...                        ...   \n",
       "2121          137.0          177.0                        4.0   \n",
       "2122          103.0          169.0                        6.0   \n",
       "2123          103.0          170.0                        5.0   \n",
       "2124          103.0          169.0                        6.0   \n",
       "2125          117.0          159.0                        2.0   \n",
       "\n",
       "      histogram_number_of_zeroes  histogram_mode  histogram_mean  \\\n",
       "0                            0.0           120.0           137.0   \n",
       "1                            1.0           141.0           136.0   \n",
       "2                            1.0           141.0           135.0   \n",
       "3                            0.0           137.0           134.0   \n",
       "4                            0.0           137.0           136.0   \n",
       "...                          ...             ...             ...   \n",
       "2121                         0.0           153.0           150.0   \n",
       "2122                         0.0           152.0           148.0   \n",
       "2123                         0.0           153.0           148.0   \n",
       "2124                         0.0           152.0           147.0   \n",
       "2125                         1.0           145.0           143.0   \n",
       "\n",
       "      histogram_median  histogram_variance  histogram_tendency  fetal_health  \n",
       "0                121.0                73.0                 1.0           2.0  \n",
       "1                140.0                12.0                 0.0           1.0  \n",
       "2                138.0                13.0                 0.0           1.0  \n",
       "3                137.0                13.0                 1.0           1.0  \n",
       "4                138.0                11.0                 1.0           1.0  \n",
       "...                ...                 ...                 ...           ...  \n",
       "2121             152.0                 2.0                 0.0           2.0  \n",
       "2122             151.0                 3.0                 1.0           2.0  \n",
       "2123             152.0                 4.0                 1.0           2.0  \n",
       "2124             151.0                 4.0                 1.0           2.0  \n",
       "2125             145.0                 1.0                 0.0           1.0  \n",
       "\n",
       "[2126 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizad el \"data frame\" usando la opción \"display\"\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de los conjuntos **X** e **y**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez creado el data frame, tenéis que crear los conjuntos $\\mathbf{X}$ e $\\mathbf{Y}$, del que luego se crea sus correspondientes conjuntos de **entrenamiento** y **test**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.fetal_health.values.astype(int)\n",
    "\n",
    "\n",
    "caract_cols = [\"baseline value\", \"accelerations\", \"fetal_movement\", \n",
    "               \"uterine_contractions\", \"light_decelerations\", \n",
    "               \"severe_decelerations\", \"prolongued_decelerations\",\n",
    "               \"abnormal_short_term_variability\", \"mean_value_of_short_term_variability\",\n",
    "               \"percentage_of_time_with_abnormal_long_term_variability\", \"mean_value_of_long_term_variability\", \n",
    "               \"histogram_width\", \"histogram_min\", \"histogram_max\", \"histogram_number_of_peaks\", \n",
    "               \"histogram_number_of_zeroes\", \"histogram_mode\", \"histogram_mean\", \n",
    "               \"histogram_median\", \"histogram_variance\", \"histogram_tendency\", \"fetal_health\"]\n",
    "\n",
    "X_all = df[caract_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2126, 22)\n"
     ]
    }
   ],
   "source": [
    "print(X_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Listado de datos y nombres\n",
    "'''\n",
    "\n",
    "datasets = [(X_all,y)]\n",
    "dataset_names = [\"Data All\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Definición del espacio de búsqueda para la optimización de los parámetros de SVM\n",
    "'''\n",
    "\n",
    "# Para definir el rango de \"C\" y de \"gamma\", tenéis que usar la opción \"np.logspace\", cubriendo, para \"C\", \n",
    "# desde 1.0e-2 hasta 1.0e+10, y para \"gamma\", desde 1.0e-9, hasta 1.0e+3.\n",
    "\n",
    "C_range = np.logspace(-2, 10, num=13)\n",
    "gamma_range = np.logspace(-9, 3, num=13)\n",
    "\n",
    "param_grid_svm = dict(gamma=gamma_range, C=C_range)\n",
    "nested_cv = 5\n",
    "\n",
    "grid_svm = GridSearchCV(SVC(), param_grid=param_grid_svm, cv=nested_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05,\n",
       "        1.e+06, 1.e+07, 1.e+08, 1.e+09, 1.e+10]),\n",
       " array([1.e-09, 1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02,\n",
       "        1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aquí se muestra el rango de valores a considerar\n",
    "C_range,gamma_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Definición del espacio de búsqueda para MLP\n",
    "'''\n",
    "alpha_range = np.logspace(-5, -1, 5)\n",
    "hidden_layer_sizes_range=[(50,),(100,),(200,),(500,),(1000,)]\n",
    "\n",
    "param_grid_mlp = dict(alpha=alpha_range, hidden_layer_sizes=hidden_layer_sizes_range)\n",
    "\n",
    "\n",
    "grid_mlp = GridSearchCV(MLPClassifier(max_iter=1000,\n",
    "                                      early_stopping=True), param_grid=param_grid_mlp, cv=nested_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Conjunto de clasificadores usados, así como sus nombres.\n",
    "'''\n",
    "\n",
    "cls_names = [\"SVM\",\"MLP\"]\n",
    "\n",
    "classifiers = [\n",
    "    make_pipeline(StandardScaler(), grid_svm),\n",
    "    make_pipeline(StandardScaler(), grid_mlp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método que ejecuta los clasificacodres y devuelve las etiquetas predichas correspondientes.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def predictions(model,X_train,y_train,X_test,y_test):    \n",
    "    \n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_model(X_train,y_train,X_test, y_test,model):\n",
    "        '''\n",
    "        Predicciones con un modelo y un conjunto de datos (X e y), para obtener posteriormente las medidas que se quieren\n",
    "        \n",
    "        Parámetros\n",
    "        ----------\n",
    "        X: numpy.array\n",
    "            Conjunto (características)\n",
    "        Y: numpy.array\n",
    "            Dataset (etiquetas)\n",
    "        model: scikit_model\n",
    "            modelo a entrenar\n",
    "        num_folds: int\n",
    "            Número de \"particiones\" de la validación cruzada (\"k-fold\" cross validation)\n",
    "        \n",
    "        Devuelve\n",
    "        -------\n",
    "        array \n",
    "            array de predicciones\n",
    "        '''\n",
    "        print('\\t'+str(model)[:20], end=' - ')\n",
    "        y_test,preds = predictions(model,X_train,y_train,X_test,y_test)\n",
    "        print('OK')\n",
    "        \n",
    "        return y_test,preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def run_all_save(filename):\n",
    "    '''\n",
    "    Realiza la validación cruzada de todos los modelos y conjuntos de datos.\n",
    "        \n",
    "        \n",
    "    Parámetros\n",
    "    ----------\n",
    "    num_folds: int\n",
    "        Igual que antes\n",
    "    filename: string\n",
    "        Nombre del fichero que guardará las \"predicciones\"\n",
    "        \n",
    "        \n",
    "    El par X_train, y_train son los atributos y clases del conjunto de entrenamiento (70% de los ejemplos)\n",
    "    El par X_test, y_test son los atributos y clases del conjunto de test (30% de los ejemplos)\n",
    "\n",
    "    stratify (estratificar) significa que se quiere que haya la misma proporcion de cada una de las clases\n",
    "    tanto en entrenamiento como en test, es decir, no es una partición completamente aleatoria.\n",
    "    \n",
    "    ''' \n",
    "    \n",
    "    all_preds = {}\n",
    "\n",
    "    for dataset,dataset_name in zip(datasets, dataset_names):\n",
    "        print(dataset_name)\n",
    "        X,y = dataset\n",
    "        \n",
    "        \n",
    "        # TENÉIS QUE COMPLETAR AQUÍ\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3)\n",
    "        \n",
    "\n",
    "        for model,cls_name in zip(classifiers,cls_names):\n",
    "            print(cls_name)\n",
    "            y_test,preds = predictions_model(X_train,y_train,X_test,y_test,model)\n",
    "            all_preds[(dataset_name,cls_name)]=(y_test,preds)\n",
    "\n",
    "    all_preds[\"cls_names\"]=cls_names\n",
    "    all_preds[\"dataset_names\"]=dataset_names\n",
    "\n",
    "    with open(filename, 'wb') as fp:\n",
    "         pickle.dump(all_preds, fp)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "All the predictions are going to be saved in a Python dictionary for \n",
    "further analysis.\n",
    "'''\n",
    "\n",
    "filename = 'PrediccionesFetalHealth.obj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data All\n",
      "SVM\n",
      "\tPipeline(steps=[('st - OK\n",
      "MLP\n",
      "\tPipeline(steps=[('st - OK\n"
     ]
    }
   ],
   "source": [
    "# Run the experiments\n",
    "\n",
    "run_all_save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de los resultados\n",
    "\n",
    "Si los experimentos se han realizado previamente, sólo es necesario ejecutar el *notebook* desde esta parte. \n",
    "\n",
    "Los resultados se *cargarían* desde el disco duro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que debe evaluar los resultados de clasificación.\n",
    "\n",
    "def evalua(y_test, y_pred):\n",
    "    \n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_mat_df(cm,labels):\n",
    "    '''\n",
    "    Creación de una matriz de confusión en un DataFrame\n",
    "        \n",
    "        \n",
    "    Parámetros\n",
    "    ----------\n",
    "    cm: ndarray 2D\n",
    "        matriz de confusión\n",
    "    labels: lista\n",
    "        Lista de nombres de clase\n",
    "        \n",
    "    Return DataFrame\n",
    "    -------\n",
    "    \n",
    "    ''' \n",
    "\n",
    "    return (pd.DataFrame(cm,index=labels, columns=labels)\n",
    "          .rename_axis(\"actual\")\n",
    "          .rename_axis(\"predicted\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(filename):\n",
    "    '''\n",
    "    Carga el fichero con las predicciones.\n",
    "    Calcula la \"accuracy\", la matriz de confusión, y otras. \n",
    "        \n",
    "        \n",
    "    Parámetros\n",
    "    ----------\n",
    "    filename: string\n",
    "        Nombre del fichero que guarda las predicciones\n",
    "        \n",
    "    Return\n",
    "    diccionario\n",
    "        Un diccionario de pares key:values\n",
    "    -------\n",
    "    \n",
    "    ''' \n",
    "\n",
    "    with open(filename, 'rb') as fp:\n",
    "        all_preds = pickle.load(fp)\n",
    "\n",
    "    cls_names = all_preds.pop(\"cls_names\")\n",
    "    dataset_names = all_preds.pop(\"dataset_names\")\n",
    "\n",
    "    data_cls_pairs = list(all_preds.keys())\n",
    "    data_cls_pairs.sort()\n",
    "\n",
    "    results = {}\n",
    "\n",
    "\n",
    "    acc_df = pd.DataFrame(index=dataset_names, columns=cls_names)\n",
    "\n",
    "    ## A DataFrame is created to store the accuracy in each clase\n",
    "    for dataset in dataset_names:\n",
    "        results[(dataset,\"acc\")] = pd.DataFrame(columns=cls_names)\n",
    "\n",
    "\n",
    "    for dataset_name,cls_name in data_cls_pairs:\n",
    "\n",
    "        #print(dataset_name,cls_name)\n",
    "        y_true, y_pred = all_preds[(dataset_name,cls_name)]\n",
    "        labels = list(np.unique(y_true))\n",
    "\n",
    "        acc = evalua(y_true, y_pred)\n",
    "        # Fill accuracy dataframe\n",
    "        acc_df.at[dataset_name,cls_name]=acc\n",
    "\n",
    "        # Get conf_mat\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        cm_df = conf_mat_df(cm,labels)\n",
    "        results[(dataset_name,cls_name,\"cm\")] = cm_df\n",
    "        \n",
    "        # Get classification report\n",
    "        report = classification_report(y_true, y_pred, output_dict=True)\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        results[(dataset_name,cls_name,\"report\")] = report_df\n",
    "\n",
    "        # Acc per class\n",
    "        cm_dig = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm_dig = cm_dig.diagonal()\n",
    "\n",
    "        dfi = results[(dataset_name,\"acc\")]\n",
    "        dfi[cls_name]=pd.Series(cm_dig,labels)    \n",
    "        results[(dataset_name,\"acc\")]=dfi.copy()\n",
    "\n",
    "\n",
    "    results[\"Acc\"] = acc_df\n",
    "    return results\n",
    "        \n",
    "        \n",
    "results = get_results(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = results[\"Acc\"].astype(float)\n",
    "df_conf = results[(\"Data All\",\"SVM\",\"cm\")].astype(float)\n",
    "df_report = results[(\"Data All\",\"SVM\",\"report\")].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Data All</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SVM       MLP\n",
       "Data All  1.0  0.984326"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted      1     2     3\n",
       "actual                      \n",
       "1          500.0   0.0   0.0\n",
       "2            0.0  90.0   0.0\n",
       "3            0.0   0.0  48.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9426</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7680</td>\n",
       "      <td>0.6531</td>\n",
       "      <td>0.7059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8235</td>\n",
       "      <td>0.7955</td>\n",
       "      <td>0.8092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.9125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.8447</td>\n",
       "      <td>0.8065</td>\n",
       "      <td>0.8239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.9086</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.9097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score\n",
       "1                0.9426  0.9710    0.9566\n",
       "2                0.7680  0.6531    0.7059\n",
       "3                0.8235  0.7955    0.8092\n",
       "accuracy         0.9125  0.9125    0.9125\n",
       "macro avg        0.8447  0.8065    0.8239\n",
       "weighted avg     0.9086  0.9125    0.9097"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report.round(4)[[\"precision\",\"recall\",\"f1-score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Análisis posteriores\n",
    "\n",
    "En este apartado vas a tener que buscar información que te permita obtener lo que se pregunta en los tres puntos siguientes:\n",
    "\n",
    "1. Estudia el efecto que tiene en la tasa de clasificación diferentes tipos de porcentajes de partición del conjunto, en conjunto de *entrenamiento* y de *test*. Puedes considerar, por ejemplo, los siguientes (normenclatura: (entrenamiento-test))\n",
    "\n",
    "    - $50\\%-50\\%$\n",
    "    - $60\\%-40\\%$\n",
    "    - $70\\%-30\\%$\n",
    "    - $80\\%-20\\%$\n",
    "\n",
    "\n",
    "2. Haz una representación gráfica con el valor de la tasa de acierto en función de diferentes porcentajes de partición del conjunto\n",
    "\n",
    "\n",
    "3. Programa la forma de ejecutar los dos métodos de clasificación, de tal forma que se ejecuten ambos $10$ veces, y se muestre la representación gráfica del punto $2$, pero en este caso considerando su valor medio y desviación estándar.\n",
    "\n",
    "    - Un ejemplo de gráfica en la que se representaría la media y la desviación estándar sería de la siguiente forma:\n",
    "\n",
    "    <img src=\"pics/GraficosBarrasError.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
